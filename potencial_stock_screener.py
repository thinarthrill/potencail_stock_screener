# -*- coding: utf-8 -*-
"""Potencial Stock Screener

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XRq4xJMEbkYttDayxN1CWBgbT3Y8NJx8
"""

#!pip install yfinance
#!pip install requests pandas
#!pip install dotenv

import requests
import pandas as pd
import re
from bs4 import BeautifulSoup
import os
import json
from datetime import datetime, timedelta
from google.cloud import storage

FINNHUB_API_KEY="d1ubjm1r01qp7ee2no50d1ubjm1r01qp7ee2no5g"
BOT_TOKEN="8063786817:AAGKrA2Y7PKM5NT_STM6mFMLVBeQzv2QBws"
SIGNAL_CHANNEL="@insiderpulseradar"
NEWS_CHANNEL="@insiderpulseaichannel"
API_KEY="AIzaSyDcEWk0DMenYS60petfPlVH5-9Zp5PgzWc"
CX="863020016f9014413"
BUCKET="thinarthrillbucket"
GCS_KEY_JSON = {"type": "service_account", "project_id": "avian-hangout-238804", "private_key_id": "95391262d77c0a9238d49dcfc4410d40f85ccd79", "private_key": "-----BEGIN PRIVATE KEY-----\nMIIEvwIBADANBgkqhkiG9w0BAQEFAASCBKkwggSlAgEAAoIBAQCeel7pgRkUs79v\nYVzxlqWv1wnUn0Hv8uaxjJy7ghF8TuA5aPTBKhiMKQ5w0lB4shDgUA5eFdz1PpXj\nyszGRvtBIRoayvH1wYbyMBGRlGJo11sZVIVi/xXkYZJtnfJADUOGAqKnNZgeWmFt\nVG+ZbWf+MQ8lVQZx5mgg1qmH0SaI8oPYIsRyd1Q9cDfWQMwjVRDBsI9Fp9gEGtQX\nsHfjpsz5s020KiAyhecywkcm3/xJ4qzHhFV4VpHesvPOM/Rpel7lhaWKQjRaSFTI\ncA3vTtj3Oq5k5auvWq+B4egOBDPq/CvAzgMxxK5AI3tTlLHytFlRIvKpbY+PU4cc\nXl3d77mDAgMBAAECggEAJ0Y5VlH1lsFTDHXLFF4asqCuoYBUVXRTgqXPw9Jgpfdg\nLyoZGfPmQHn+R6x/X+H1N7nvTZbKewanG9xK8kpuAv6Cmyg3XYm3+TY7bGIjH0tb\nmsPtCJMh6EbcBIlzmzcOSFxH1ft8tuz8Hx2hSJsp/f9Hex9+qOSKYrUAL5YAIEjh\noVyGcid7ecEX55gmtTW1osPvXlleHY/72KCxcc9lcVi8PJgd+wiXncFbNaf7QI2P\n98ZCY/TI7SEHwWGK8bugK1eVL7TptvgEUlqbv+icVpePferOenLri15ehWeCTEvN\nXgeyB0b/CrsT3DQphK1GdqayvbLOiWaia9d3hBQTJQKBgQDXLHI3X64yjLm0+bG3\nMz4RJ0HlJkzgPKzDhy4vJiPdPd6ws2VObcwaAFWEkPzdYo4RcmezUN91wne2p439\npSNwREZyCZIJOLV4S8xCT+bnD3H8TjXdzQdZytccBwK+UY0rxbH7ECCfDD4ERMTJ\nrbJo5yBqx3Co55/ukIdlmfcMxQKBgQC8jBGFwccMiKkORDOgGH1H9aN1Ijxv8ULO\nnThuAnsjW84YJ6f9Rv+R8RlrKS5Qsg67q8Sro7kTdU/BSzo3j4ECthaY+3stdTox\n51enrU1x6f4Eejg6DidTwYZ73WzBsaSAc9SSynvmgmG9Zk6hiirAuiBEhmzW8+iX\nQQ7pZK0hpwKBgQC6il26g8iRKk8VBiN7n4D/ffkyn7Gl9PQRzu/LEFWnSCv3JI9/\nHtEC+acp9khB5V8k4PnmCwavIJiIUVpXuwKuIYKw+nsQY4lvcMbz9jFHv6wh/+vT\nDhyBS8iRE8LdG/Y3LHzQG3ssZ4CcUsIH1f4F09nWuHCC/cs5FzNKceArwQKBgQCW\niK4kwIWPODzhKwqcs3Cy1ydeCat/JHxWQaggDNMLc+yj1GWHDfxWJMxKhmJ4AvFI\nXOd0sg69vlei19DvMx+pbn+0PHQn4wRHe5C8St0eKdeo83uYvlwfvs8EbdC7BH12\nIQSC/i7V5xrqAJie2JUxsmi4zSpwo+P7fvHM3Zhs2QKBgQChtTivH4D2czJIHOE5\nbsu2OrQyQuCPbm/RYmV4rFTGtV70lkvBWU/18tZiiNTb/Thmwa+XbkkOn2/6i24t\neVO0GbB2WWp+8od0EUOu+kt9tfiMXsMDW+doCFaCUqfJ1KB1f8lXCpv+SKA1NSwi\nTcHytvUKesEw03HKdBAbdpsHSg==\n-----END PRIVATE KEY-----\n", "client_email": "115521860480-compute@developer.gserviceaccount.com", "client_id": "112363683215994423676", "auth_uri": "https://accounts.google.com/o/oauth2/auth", "token_uri": "https://oauth2.googleapis.com/token", "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs", "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/115521860480-compute%40developer.gserviceaccount.com", "universe_domain": "googleapis.com"}
STOCK_FILE="InsiderPulseDB/Options_History.csv"
PORTFOLIO_FILE="InsiderPulseDB/Stocks.csv"
SIGNALS_FILE="InsiderPulseDB/active_signals.csv"
SPAC_FILE="InsiderPulseDB/SPAC.csv"
FDA_CALENDAR="InsiderPulseDB/fda_calendar.csv"

def init_gcs_client():
    key_dict = GCS_KEY_JSON
    if not key_dict:
        raise ValueError("‚ùå GCS_KEY_JSON –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–ª–∏ –ø—É—Å—Ç–∞")

    with open("gcs_key.json", "w") as f:
        f.write(json.dumps(key_dict))  # ‚úÖ serialize to JSON string

    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "gcs_key.json"
    return storage.Client()


def download_from_gcs(bucket_name, gcs_path, local_path):
    client = init_gcs_client()
    bucket = client.get_bucket(bucket_name)
    blob = bucket.blob(gcs_path)
    blob.download_to_filename(local_path)
    print(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {gcs_path} ‚Üí {local_path}")

def upload_to_gcs(local_file_path, bucket_name, gcs_filename):
    client = init_gcs_client()
    bucket = client.get_bucket(bucket_name)
    blob = bucket.blob(gcs_filename)
    blob.upload_from_filename(local_file_path)
    print("üì§ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –≤ GCS:", blob.public_url)
    return blob.public_url

# üìå –ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
current_month = datetime.now().strftime("%B")
current_year = datetime.now().year

queries = [
    f"Top stocks to buy {current_month} {current_year}",
    f"Best stocks to invest in {current_month} {current_year}",
    f"Growth stocks to buy now {current_year}",
    "Best stocks to buy now",
]

# üì• –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –µ—Å—Ç—å
try:
    download_from_gcs(BUCKET, PORTFOLIO_FILE, PORTFOLIO_FILE)
    df_old = pd.read_csv(PORTFOLIO_FILE)
except FileNotFoundError:
    df_old = pd.DataFrame(columns=["ticker", "date", "source", "link"])
existing = set(df_old["ticker"])
new_data = []

# üîç –ü–æ–∏—Å–∫ –∏ –ø–∞—Ä—Å–∏–Ω–≥
for query in queries:
    print(f"üîç –ü–æ–∏—Å–∫: {query}")
    params = {
        "key": API_KEY,
        "cx": CX,
        "q": query,
        "num": 10,
    }
    response = requests.get("https://www.googleapis.com/customsearch/v1", params=params)
    response.raise_for_status()
    data = response.json()

    for item in data.get("items", []):
        title = item.get("title", "")
        snippet = item.get("snippet", "")
        link = item.get("link", "")
        source = re.sub(r"https?://(www\.)?", "", link).split("/")[0]

        # üîé –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å —Ç–∏–∫–µ—Ä—ã (–≤—Å—ë –≤ –≤–µ—Ä—Ö–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ, –æ—Ç 1 –¥–æ 5 –±—É–∫–≤)
        tickers = set(re.findall(r"\b[A-Z]{1,5}\b", title + " " + snippet))

        # –§–∏–ª—å—Ç—Ä –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ ‚Äî –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å
        tickers = [t for t in tickers if t.isalpha() and 1 <= len(t) <= 5]

        for ticker in tickers:
            if ticker not in existing:
                new_data.append({
                  "ticker": ticker,
                  "date": datetime.now().strftime("%Y-%m-%d"),
                  "source": source,
                  "link": link
                })

# === 2. üöÄ SPACInsider ===

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–∏–∫–µ—Ä–æ–≤ –∏–∑ SPAC.csv
try:
    download_from_gcs(BUCKET, SPAC_FILE, SPAC_FILE)
    df_spac = pd.read_csv(SPAC_FILE)
    tickers = df_spac["Company"].dropna().unique()

    for ticker in tickers:
        ticker = ticker.strip().upper()
        if ticker not in existing:
            new_data.append({
                "ticker": ticker,
                "date": datetime.now().strftime("%Y-%m-%d"),
                "source": "SPAC",
                "link": "https://www.spacinsider.com/stats/"
            })
            existing.add(ticker)

    if new_data:
        df_all = pd.concat([df_old, pd.DataFrame(new_data)], ignore_index=True)
        df_all.to_csv(PORTFOLIO_FILE, index=False)
        upload_to_gcs(PORTFOLIO_FILE, BUCKET, PORTFOLIO_FILE)
        print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ SPAC —Ç–∏–∫–µ—Ä–æ–≤: {len(new_data)}")
    else:
        print("‚ÑπÔ∏è –ù–æ–≤—ã—Ö SPAC —Ç–∏–∫–µ—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ SPAC –∏–∑ —Ñ–∞–π–ª–∞: {e}")

# === 3. üíä FDA Calendar (–∏–∑ fda_updated.csv) ===
try:
    download_from_gcs(BUCKET, FDA_CALENDAR, FDA_CALENDAR)
    fda_df = pd.read_csv(FDA_CALENDAR)
    fda_df["Catalyst Date"] = pd.to_datetime(fda_df["Catalyst Date"], errors="coerce")

    for _, row in fda_df.iterrows():
        event_date = row["Catalyst Date"]
        if pd.isna(event_date):
            continue
        if 0 <= (event_date.date() - datetime.now().date()).days <= 30:
            ticker = str(row["Company"]).strip()
            key = ticker
            if key not in existing:
                new_data.append({
                    "ticker": ticker,
                    "date": datetime.now().strftime("%Y-%m-%d"),
                    "source": "FDA",
                    "link": f"https://finance.yahoo.com/quote/{ticker}"
                })
                existing.add(key)
except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ FDA CSV: {e}")

# üì¶ –°–æ—Ö—Ä–∞–Ω—è–µ–º
if new_data:
    df_new = pd.DataFrame(new_data)
    df_total = pd.concat([df_old, df_new], ignore_index=True)
    df_total.to_csv(PORTFOLIO_FILE, index=False)
    upload_to_gcs(PORTFOLIO_FILE, BUCKET, PORTFOLIO_FILE)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(new_data)}")
else:
    print("‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è.")

# === –î–Ω–µ–π –¥–æ –Ω–æ–≤–æ—Å—Ç–∏
TARGET_DAYS = 20

def is_liquid_stock(symbol, api_key, min_market_cap=1):
    """–§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –±–∏—Ä–∂–µ"""
    url = f"https://finnhub.io/api/v1/stock/profile2?symbol={symbol}&token={api_key}"
    try:
        res = requests.get(url).json()
        market_cap = res.get("marketCapitalization", 0)
        exchange = res.get("exchange", "")
        #print(f"‚ö†Ô∏è {symbol}: –∫–∞–ø={market_cap} < {min_market_cap} exc {exchange}")
        if market_cap and market_cap >= min_market_cap and exchange in ["NASDAQ NMS - GLOBAL MARKET", "NEW YORK STOCK EXCHANGE, INC."]:
            return True
    except:
        pass
    return False

# === –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
if os.path.exists(PORTFOLIO_FILE):
    df_existing = pd.read_csv(PORTFOLIO_FILE)
else:
    df_existing = pd.DataFrame(columns=["ticker", "date", "source", "link"])

existing_tickers = set(df_existing["ticker"].dropna().tolist())

# === –î–∞—Ç—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
today = datetime.today().date()
future = today + timedelta(days=TARGET_DAYS)

# === –ó–∞–ø—Ä–æ—Å –∫ Finnhub
url = f"https://finnhub.io/api/v1/calendar/earnings?from={today}&to={future}&token={FINNHUB_API_KEY}"
try:
    response = requests.get(url)
    earnings_data = response.json().get("earningsCalendar", [])
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
    earnings_data = []

# === –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–∞—Ç–µ –≤—Ä—É—á–Ω—É—é
records = []
for item in earnings_data:
    symbol = item.get("symbol")
    report_date_str = item.get("date")

    if not symbol or not report_date_str:
        continue

    try:
        report_date = datetime.strptime(report_date_str, "%Y-%m-%d").date()
    except:
        continue
    #print(f"üîé {symbol} ‚Äî –æ—Ç—á—ë—Ç–Ω–æ—Å—Ç—å: {report_date} | –í –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ? ", end="\n")
    if not (today <= report_date <= future):
        continue

    if symbol not in existing_tickers and is_liquid_stock(symbol, FINNHUB_API_KEY):
        records.append({
            "ticker": symbol,
            "date": today.isoformat(),  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–µ–≥–æ–¥–Ω—è—à–Ω—é—é –¥–∞—Ç—É
            "source": "earnings",
            "link": f"https://finance.yahoo.com/quote/{symbol}"
        })

# === –°–æ—Ö—Ä–∞–Ω—è–µ–º
if records:
    df_new = pd.DataFrame(records)
    df_result = pd.concat([df_existing, df_new], ignore_index=True)
    df_result.to_csv(PORTFOLIO_FILE, index=False)
    upload_to_gcs(PORTFOLIO_FILE, BUCKET, PORTFOLIO_FILE)
    print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(df_new)} –Ω–æ–≤—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤.")
else:
    print("‚ÑπÔ∏è –ù–æ–≤—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ —Å –æ–∂–∏–¥–∞–µ–º–æ–π –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å—é –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

import yfinance as yf

# === –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–∏–∫–µ—Ä—ã ===
try:
    df_tickers = pd.read_csv(PORTFOLIO_FILE)
    tickers = df_tickers["ticker"].dropna().unique().tolist()
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–∏–∫–µ—Ä–æ–≤: {e}")
    tickers = []

# === –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ–ø—Ü–∏–æ–Ω–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å) ===
download_from_gcs(BUCKET, STOCK_FILE, STOCK_FILE)
if os.path.exists(STOCK_FILE):
    df_history = pd.read_csv(STOCK_FILE)
else:
    df_history = pd.DataFrame(columns=[
        "date", "ticker", "call_volume", "put_volume",
        "total_volume", "call_open_interest", "put_open_interest"
    ])

today = datetime.now().strftime("%Y-%m-%d")
existing_keys = set(zip(df_history["date"], df_history["ticker"]))
new_data = []

# === –ü–æ–ª—É—á–∞–µ–º –æ–ø—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–∫–µ—Ä–∞ ===
for ticker in tickers:
    key = (today, ticker)
    if key in existing_keys:
        continue  # —É–∂–µ –µ—Å—Ç—å –≤ –∏—Å—Ç–æ—Ä–∏–∏

    try:
        t = yf.Ticker(ticker)
        expirations = t.options
        if not expirations:
            continue
        chain = t.option_chain(expirations[0])
        calls = chain.calls
        puts = chain.puts

        call_volume = calls["volume"].sum()
        put_volume = puts["volume"].sum()
        call_oi = calls["openInterest"].sum()
        put_oi = puts["openInterest"].sum()

        new_data.append({
            "date": today,
            "ticker": ticker,
            "call_volume": call_volume,
            "put_volume": put_volume,
            "total_volume": call_volume + put_volume,
            "call_open_interest": call_oi,
            "put_open_interest": put_oi
        })

        print(f"‚úÖ {ticker}: vol={call_volume+put_volume}, OI={call_oi+put_oi}")

    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ {ticker}: {e}")

# === –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ ===
if new_data:
    df_new = pd.DataFrame(new_data)
    df_full = pd.concat([df_history, df_new], ignore_index=True)
    df_full.to_csv(STOCK_FILE, index=False)
    upload_to_gcs(STOCK_FILE, BUCKET, STOCK_FILE)
    print(f"\n‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(df_new)} ‚Üí —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {STOCK_FILE}")
else:
    print("‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–ø–∏—Å–∏.")

import uuid

# === Telegram –æ—Ç–ø—Ä–∞–≤–∫–∞
def send_telegram_message(text, chat_id, reply_to=None):
    payload = {
        "chat_id": chat_id,
        "text": text,
        "parse_mode": "HTML"
    }
    if reply_to:
        payload["reply_to_message_id"] = reply_to
    resp = requests.post(f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage", data=payload)
    return resp.json()["result"] if resp.ok else None

def forward_telegram_message(from_chat_id, message_id, to_chat_id):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/forwardMessage"
    payload = {
        "chat_id": to_chat_id,
        "from_chat_id": from_chat_id,
        "message_id": int(message_id)
    }
    resp = requests.post(url, data=payload)
    return resp.json()["result"] if resp.ok else None

# === –ß—Ç–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
def load_signals():
    download_from_gcs(BUCKET, SIGNALS_FILE, SIGNALS_FILE)
    if os.path.exists(SIGNALS_FILE):
        df = pd.read_csv(SIGNALS_FILE)
        df["date_sent"] = pd.to_datetime(df["date_sent"], errors='coerce')
        df["last_checked"] = pd.to_datetime(df["last_checked"])
        return df
    else:
        return pd.DataFrame(columns=["id", "ticker", "date_sent", "signal_type", "price_entry", "max_profit", "last_checked", "signal_url"])

def save_signals(df):
    df.to_csv(SIGNALS_FILE, index=False)
    upload_to_gcs(SIGNALS_FILE, BUCKET, SIGNALS_FILE)

# === –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
def compute_signals(df, window_days=5, min_vol=1000, min_oi=500, min_ratio=2):
    signals = []
    tickers = df["ticker"].unique()

    for ticker in tickers:
        df_t = df[df["ticker"] == ticker].copy()
        df_t["date"] = pd.to_datetime(df_t["date"], errors='coerce')
        df_t = df_t.dropna(subset=["date", "total_volume", "call_open_interest", "put_open_interest"])
        df_t = df_t.sort_values("date").tail(window_days)

        if len(df_t) < window_days:
            continue

        volumes = df_t["total_volume"].values
        calls = df_t["call_open_interest"].values
        puts = df_t["put_open_interest"].values
        ratios = [c/p if p > 0 else float('inf') for c, p in zip(calls, puts)]

        if (
            volumes[-1] > volumes[0] and
            calls[-1] > calls[0] and
            ratios[-1] > min_ratio and
            volumes[-1] > min_vol and
            calls[-1] > min_oi
        ):
            signals.append({
                "ticker": ticker,
                "volume_trend": f"{int(volumes[0])} ‚Üí {int(volumes[-1])}",
                "oi_trend": f"{int(calls[0])} ‚Üí {int(calls[-1])}",
                "ratio": round(ratios[-1], 2)
            })

    return signals

def send_signals():
    try:
        df = pd.read_csv(STOCK_FILE)
        df = df.dropna(subset=["total_volume", "call_open_interest", "put_open_interest"])
        df["total_volume"] = pd.to_numeric(df["total_volume"], errors='coerce')
        df["call_open_interest"] = pd.to_numeric(df["call_open_interest"], errors='coerce')
        df["put_open_interest"] = pd.to_numeric(df["put_open_interest"], errors='coerce')

        signals = compute_signals(df)
        if not signals:
            print("üö´ –°–∏–≥–Ω–∞–ª–æ–≤ –ø–æ –¥–∏–Ω–∞–º–∏–∫–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            return

        all_signals = load_signals()
        new_rows = []

        for s in signals:
            ticker = s["ticker"]
            signal_type = "BUY"

            if ((all_signals["ticker"] == ticker) & (all_signals["signal_type"] == signal_type)).any():
                print(f"‚è© –£–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω —Ä–∞–Ω–µ–µ: {ticker}")
                continue

            entry_price = yf.Ticker(ticker).history(period="1d")["Close"][-1]
            signal_id = str(uuid.uuid4())[:8]
            today = datetime.now().strftime("%Y-%m-%d")
            url = f"https://t.me/{SIGNAL_CHANNEL.strip('@')}"  # –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Å—Å—ã–ª–∫—É –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø–æ—Å—Ç

            msg = (
                f"üìä –°–∏–≥–Ω–∞–ª: {ticker}\n"
                f"–û–±—ä—ë–º: {s['volume_trend']}\n"
                f"Call OI: {s['oi_trend']}\n"
                f"Call/Put: {s['ratio']}"
            )

            result = send_telegram_message(msg, SIGNAL_CHANNEL)

            if result:
                message_id = result["message_id"]
                channel_username = SIGNAL_CHANNEL.strip("@")
                signal_url = f"https://t.me/{channel_username}/{message_id}"
                print(f"üì§ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {ticker}")
                new_rows.append({
                    "id": signal_id,
                    "ticker": ticker,
                    "date_sent": today,
                    "signal_type": signal_type,
                    "price_entry": entry_price,
                    "max_profit": 0.0,
                    "last_checked": today,
                    "signal_url": signal_url,
                    "message_id": message_id  # üí• –∏–Ω–∞—á–µ –ø–æ—Ç–æ–º –Ω–µ –±—É–¥–µ—Ç reply
                })

        if new_rows:
            all_signals = pd.concat([all_signals, pd.DataFrame(new_rows)], ignore_index=True)
            save_signals(all_signals)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

# === –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–∏–±—ã–ª–∏ –∏ —É–¥–∞–ª–µ–Ω–∏–µ —É–±—ã—Ç–æ—á–Ω—ã—Ö
def drop_from_csv(filepath, tickers, column="ticker"):
    if os.path.exists(filepath):
        df = pd.read_csv(filepath)
        df = df[~df[column].isin(tickers)]
        df.to_csv(filepath, index=False)
        upload_to_gcs(filepath, BUCKET, filepath)

def monitor_signals():
    if not os.path.exists(SIGNALS_FILE):
        return

    df = load_signals()
    updated = []
    dropped = []

    for _, row in df.iterrows():
        ticker = row["ticker"]
        entry = row["price_entry"]
        max_profit = row["max_profit"]
        last_check = pd.to_datetime(row["last_checked"])
        message_id = int(row["message_id"])

        if datetime.now() - last_check < timedelta(days=10):
            updated.append(row)
            continue

        try:
            price_now = yf.Ticker(ticker).history(period="1d")["Close"][-1]
            profit_pct = ((price_now - entry) / entry) * 100

            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞—Ç—É –ø—Ä–æ–≤–µ—Ä–∫–∏
            row["last_checked"] = datetime.now().strftime("%Y-%m-%d")

            # === –£—Å–ª–æ–≤–∏–µ 1: –ü–µ—Ä–≤–∞—è —Ñ–∏–∫—Å–∞—Ü–∏—è –ø—Ä–∏–±—ã–ª–∏ >20%
            if profit_pct >= 20 and max_profit == 0:
                forward = forward_telegram_message(SIGNAL_CHANNEL, message_id, NEWS_CHANNEL)
                if forward:
                    forward_msg_id = forward["message_id"]
                    news_reply = f"üéâ {ticker} –≤—ã—Ä–æ—Å –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 20%!\nüìà –ü—Ä–∏–±—ã–ª—å: {profit_pct:.2f}%\n–ü–æ–∑–¥—Ä–∞–≤–ª—è–µ–º –≤—Å–µ—Ö, –∫—Ç–æ –∑–∞—à—ë–ª!"
                    send_telegram_message(news_reply, NEWS_CHANNEL, reply_to=forward_msg_id)

                # –†–µ–ø–ª–∞–π –≤ –∫–∞–Ω–∞–ª —Å —Å–∏–≥–Ω–∞–ª–æ–º
                reply_signal = f"‚úÖ {ticker} –¥–æ—Å—Ç–∏–≥ —Ü–µ–ª–∏ +20%!\n–¢–µ–∫—É—â–∞—è –ø—Ä–∏–±—ã–ª—å: {profit_pct:.2f}%"
                send_telegram_message(reply_signal, SIGNAL_CHANNEL, reply_to=message_id)

                row["max_profit"] = profit_pct

            # === –£—Å–ª–æ–≤–∏–µ 2: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–∞–∫—Å–∏–º—É–º–∞ –ø—Ä–∏–±—ã–ª–∏
            elif profit_pct > max_profit:
                forward = forward_telegram_message(SIGNAL_CHANNEL, message_id, NEWS_CHANNEL)
                if forward:
                    forward_msg_id = forward["message_id"]
                    news_reply = f"üìà {ticker} –æ–±–Ω–æ–≤–∏–ª –º–∞–∫—Å–∏–º—É–º: +{profit_pct:.2f}%"
                    send_telegram_message(news_reply, NEWS_CHANNEL, reply_to=forward_msg_id)

                # –†–µ–ø–ª–∞–π –≤ –∫–∞–Ω–∞–ª —Å —Å–∏–≥–Ω–∞–ª–æ–º
                reply_signal = f"üìà –ù–æ–≤—ã–π –º–∞–∫—Å–∏–º—É–º –ø—Ä–∏–±—ã–ª–∏ –ø–æ {ticker}: +{profit_pct:.2f}%"
                send_telegram_message(reply_signal, SIGNAL_CHANNEL, reply_to=message_id)

                row["max_profit"] = profit_pct

            # === –£—Å–ª–æ–≤–∏–µ 3: –ü—Ä–∏–±—ã–ª—å –ø–∞–¥–∞–µ—Ç ‚Üí —É–¥–∞–ª–∏—Ç—å
            elif profit_pct < max_profit:
                print(f"üóë {ticker} —É–¥–∞–ª—ë–Ω ‚Äî –ø—Ä–∏–±—ã–ª—å —É–ø–∞–ª–∞")
                dropped.append(ticker)
                continue

            updated.append(row)

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ {ticker}: {e}")
            updated.append(row)

    save_signals(pd.DataFrame(updated))

    if dropped:
        drop_from_csv(STOCK_FILE, dropped)
        drop_from_csv(PORTFOLIO_FILE, dropped)
        drop_from_csv(SIGNALS_FILE, dropped)
        print(f"üßπ –£–¥–∞–ª–µ–Ω—ã —Ç–∏–∫–µ—Ä—ã: {dropped}")

# === –ó–∞–ø—É—Å–∫
send_signals()
monitor_signals()

print("üéØ DONE ver. 2")


