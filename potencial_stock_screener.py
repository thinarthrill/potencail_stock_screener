# -*- coding: utf-8 -*-
"""Potencial Stock Screener

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XRq4xJMEbkYttDayxN1CWBgbT3Y8NJx8
"""

#!pip install yfinance
#!pip install requests pandas
#!pip install dotenv

import requests
import pandas as pd
import re
from bs4 import BeautifulSoup
import os
import json
from datetime import datetime, timedelta
from google.cloud import storage

FINNHUB_API_KEY=os.getenv("FINNHUB_API_KEY")
BOT_TOKEN=os.getenv("BOT_TOKEN")
SIGNAL_CHANNEL=os.getenv("SIGNAL_CHANNEL")
NEWS_CHANNEL=os.getenv("NEWS_CHANNEL")
API_KEY=os.getenv("API_KEY")
CX=os.getenv("CX")
BUCKET=os.getenv("BUCKET")
GCS_KEY_JSON=os.getenv("GCS_KEY_JSON")
STOCK_FILE="InsiderPulseDB/Options_History.csv"
PORTFOLIO_FILE="InsiderPulseDB/Stocks.csv"
SIGNALS_FILE="InsiderPulseDB/active_signals.csv"
SPAC_FILE="InsiderPulseDB/SPAC.csv"
FDA_CALENDAR="InsiderPulseDB/fda_calendar.csv"

def init_gcs_client():
    key_str = os.getenv("GCS_KEY_JSON")
    if not key_str:
        raise ValueError("‚ùå GCS_KEY_JSON –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–ª–∏ –ø—É—Å—Ç–∞")

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫—É –∏–∑ .env –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å–ª–æ–≤–∞—Ä—å
    key_dict = json.loads(key_str)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Ñ–∞–π–ª
    with open("gcs_key.json", "w") as f:
        json.dump(key_dict, f)

    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "gcs_key.json"
    return storage.Client()

def download_from_gcs(bucket_name, gcs_path, local_path):
    client = init_gcs_client()
    bucket = client.get_bucket(bucket_name)
    blob = bucket.blob(gcs_path)
    blob.download_to_filename(local_path)
    print(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {gcs_path} ‚Üí {local_path}")

def upload_to_gcs(local_file_path, bucket_name, gcs_filename):
    client = init_gcs_client()
    bucket = client.get_bucket(bucket_name)
    blob = bucket.blob(gcs_filename)
    blob.upload_from_filename(local_file_path)
    print("üì§ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –≤ GCS:", blob.public_url)
    return blob.public_url

# === –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
os.makedirs("InsiderPulseDB", exist_ok=True)

# üìå –ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
current_month = datetime.now().strftime("%B")
current_year = datetime.now().year

queries = [
    f"Top stocks to buy {current_month} {current_year}",
    f"Best stocks to invest in {current_month} {current_year}",
    f"Growth stocks to buy now {current_year}",
    "Best stocks to buy now",
]

# üì• –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –µ—Å—Ç—å
try:
    download_from_gcs(BUCKET, PORTFOLIO_FILE, PORTFOLIO_FILE)
    df_old = pd.read_csv(PORTFOLIO_FILE)
except FileNotFoundError:
    df_old = pd.DataFrame(columns=["ticker", "date", "source", "link"])
existing = set(df_old["ticker"])
new_data = []

# üîç –ü–æ–∏—Å–∫ –∏ –ø–∞—Ä—Å–∏–Ω–≥
for query in queries:
    print(f"üîç –ü–æ–∏—Å–∫: {query}")
    params = {
        "key": API_KEY,
        "cx": CX,
        "q": query,
        "num": 10,
    }
    response = requests.get("https://www.googleapis.com/customsearch/v1", params=params)
    response.raise_for_status()
    data = response.json()

    for item in data.get("items", []):
        title = item.get("title", "")
        snippet = item.get("snippet", "")
        link = item.get("link", "")
        source = re.sub(r"https?://(www\.)?", "", link).split("/")[0]

        # üîé –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å —Ç–∏–∫–µ—Ä—ã (–≤—Å—ë –≤ –≤–µ—Ä—Ö–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ, –æ—Ç 1 –¥–æ 5 –±—É–∫–≤)
        tickers = set(re.findall(r"\b[A-Z]{1,5}\b", title + " " + snippet))

        # –§–∏–ª—å—Ç—Ä –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ ‚Äî –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å
        tickers = [t for t in tickers if t.isalpha() and 1 <= len(t) <= 5]

        for ticker in tickers:
            if ticker not in existing:
                new_data.append({
                  "ticker": ticker,
                  "date": datetime.now().strftime("%Y-%m-%d"),
                  "source": source,
                  "link": link
                })

# === 2. üöÄ SPACInsider ===

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–∏–∫–µ—Ä–æ–≤ –∏–∑ SPAC.csv
try:
    download_from_gcs(BUCKET, SPAC_FILE, SPAC_FILE)
    df_spac = pd.read_csv(SPAC_FILE)
    tickers = df_spac["Company"].dropna().unique()

    for ticker in tickers:
        ticker = ticker.strip().upper()
        if ticker not in existing:
            new_data.append({
                "ticker": ticker,
                "date": datetime.now().strftime("%Y-%m-%d"),
                "source": "SPAC",
                "link": "https://www.spacinsider.com/stats/"
            })
            existing.add(ticker)

    if new_data:
        df_all = pd.concat([df_old, pd.DataFrame(new_data)], ignore_index=True)
        df_all.to_csv(PORTFOLIO_FILE, index=False)
        upload_to_gcs(PORTFOLIO_FILE, BUCKET, PORTFOLIO_FILE)
        print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ SPAC —Ç–∏–∫–µ—Ä–æ–≤: {len(new_data)}")
    else:
        print("‚ÑπÔ∏è –ù–æ–≤—ã—Ö SPAC —Ç–∏–∫–µ—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ SPAC –∏–∑ —Ñ–∞–π–ª–∞: {e}")

# === 3. üíä FDA Calendar (–∏–∑ fda_updated.csv) ===
try:
    download_from_gcs(BUCKET, FDA_CALENDAR, FDA_CALENDAR)
    fda_df = pd.read_csv(FDA_CALENDAR)
    fda_df["Catalyst Date"] = pd.to_datetime(fda_df["Catalyst Date"], errors="coerce")

    for _, row in fda_df.iterrows():
        event_date = row["Catalyst Date"]
        if pd.isna(event_date):
            continue
        if 0 <= (event_date.date() - datetime.now().date()).days <= 30:
            ticker = str(row["Company"]).strip()
            key = ticker
            if key not in existing:
                new_data.append({
                    "ticker": ticker,
                    "date": datetime.now().strftime("%Y-%m-%d"),
                    "source": "FDA",
                    "link": f"https://finance.yahoo.com/quote/{ticker}"
                })
                existing.add(key)
except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ FDA CSV: {e}")

# üì¶ –°–æ—Ö—Ä–∞–Ω—è–µ–º
if new_data:
    df_new = pd.DataFrame(new_data)
    df_total = pd.concat([df_old, df_new], ignore_index=True)
    df_total.to_csv(PORTFOLIO_FILE, index=False)
    upload_to_gcs(PORTFOLIO_FILE, BUCKET, PORTFOLIO_FILE)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(new_data)}")
else:
    print("‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è.")

# === –î–Ω–µ–π –¥–æ –Ω–æ–≤–æ—Å—Ç–∏
TARGET_DAYS = 20

def is_liquid_stock(symbol, api_key, min_market_cap=1):
    """–§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –±–∏—Ä–∂–µ"""
    url = f"https://finnhub.io/api/v1/stock/profile2?symbol={symbol}&token={api_key}"
    try:
        res = requests.get(url).json()
        market_cap = res.get("marketCapitalization", 0)
        exchange = res.get("exchange", "")
        #print(f"‚ö†Ô∏è {symbol}: –∫–∞–ø={market_cap} < {min_market_cap} exc {exchange}")
        if market_cap and market_cap >= min_market_cap and exchange in ["NASDAQ NMS - GLOBAL MARKET", "NEW YORK STOCK EXCHANGE, INC."]:
            return True
    except:
        pass
    return False

# === –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
if os.path.exists(PORTFOLIO_FILE):
    df_existing = pd.read_csv(PORTFOLIO_FILE)
else:
    df_existing = pd.DataFrame(columns=["ticker", "date", "source", "link"])

existing_tickers = set(df_existing["ticker"].dropna().tolist())

# === –î–∞—Ç—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
today = datetime.today().date()
future = today + timedelta(days=TARGET_DAYS)

# === –ó–∞–ø—Ä–æ—Å –∫ Finnhub
url = f"https://finnhub.io/api/v1/calendar/earnings?from={today}&to={future}&token={FINNHUB_API_KEY}"
try:
    response = requests.get(url)
    earnings_data = response.json().get("earningsCalendar", [])
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
    earnings_data = []

# === –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–∞—Ç–µ –≤—Ä—É—á–Ω—É—é
records = []
for item in earnings_data:
    symbol = item.get("symbol")
    report_date_str = item.get("date")

    if not symbol or not report_date_str:
        continue

    try:
        report_date = datetime.strptime(report_date_str, "%Y-%m-%d").date()
    except:
        continue
    #print(f"üîé {symbol} ‚Äî –æ—Ç—á—ë—Ç–Ω–æ—Å—Ç—å: {report_date} | –í –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ? ", end="\n")
    if not (today <= report_date <= future):
        continue

    if symbol not in existing_tickers and is_liquid_stock(symbol, FINNHUB_API_KEY):
        records.append({
            "ticker": symbol,
            "date": today.isoformat(),  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–µ–≥–æ–¥–Ω—è—à–Ω—é—é –¥–∞—Ç—É
            "source": "earnings",
            "link": f"https://finance.yahoo.com/quote/{symbol}"
        })

# === –°–æ—Ö—Ä–∞–Ω—è–µ–º
if records:
    df_new = pd.DataFrame(records)
    df_result = pd.concat([df_existing, df_new], ignore_index=True)
    df_result.to_csv(PORTFOLIO_FILE, index=False)
    upload_to_gcs(PORTFOLIO_FILE, BUCKET, PORTFOLIO_FILE)
    print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(df_new)} –Ω–æ–≤—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤.")
else:
    print("‚ÑπÔ∏è –ù–æ–≤—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ —Å –æ–∂–∏–¥–∞–µ–º–æ–π –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å—é –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

import yfinance as yf

# === –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–∏–∫–µ—Ä—ã ===
try:
    df_tickers = pd.read_csv(PORTFOLIO_FILE)
    tickers = df_tickers["ticker"].dropna().unique().tolist()
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–∏–∫–µ—Ä–æ–≤: {e}")
    tickers = []

# === –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ–ø—Ü–∏–æ–Ω–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å) ===
download_from_gcs(BUCKET, STOCK_FILE, STOCK_FILE)
if os.path.exists(STOCK_FILE):
    df_history = pd.read_csv(STOCK_FILE)
else:
    df_history = pd.DataFrame(columns=[
        "date", "ticker", "call_volume", "put_volume",
        "total_volume", "call_open_interest", "put_open_interest"
    ])

today = datetime.now().strftime("%Y-%m-%d")
existing_keys = set(zip(df_history["date"], df_history["ticker"]))
new_data = []

# === –ü–æ–ª—É—á–∞–µ–º –æ–ø—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–∫–µ—Ä–∞ ===
for ticker in tickers:
    key = (today, ticker)
    if key in existing_keys:
        continue  # —É–∂–µ –µ—Å—Ç—å –≤ –∏—Å—Ç–æ—Ä–∏–∏

    try:
        t = yf.Ticker(ticker)
        expirations = t.options
        if not expirations:
            continue
        chain = t.option_chain(expirations[0])
        calls = chain.calls
        puts = chain.puts

        call_volume = calls["volume"].sum()
        put_volume = puts["volume"].sum()
        call_oi = calls["openInterest"].sum()
        put_oi = puts["openInterest"].sum()

        new_data.append({
            "date": today,
            "ticker": ticker,
            "call_volume": call_volume,
            "put_volume": put_volume,
            "total_volume": call_volume + put_volume,
            "call_open_interest": call_oi,
            "put_open_interest": put_oi
        })

        print(f"‚úÖ {ticker}: vol={call_volume+put_volume}, OI={call_oi+put_oi}")

    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ {ticker}: {e}")

# === –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ ===
if new_data:
    df_new = pd.DataFrame(new_data)
    df_full = pd.concat([df_history, df_new], ignore_index=True)
    df_full.to_csv(STOCK_FILE, index=False)
    upload_to_gcs(STOCK_FILE, BUCKET, STOCK_FILE)
    print(f"\n‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(df_new)} ‚Üí —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {STOCK_FILE}")
else:
    print("‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–ø–∏—Å–∏.")

import uuid

# === Telegram –æ—Ç–ø—Ä–∞–≤–∫–∞
def send_telegram_message(text, chat_id, reply_to=None):
    payload = {
        "chat_id": chat_id,
        "text": text,
        "parse_mode": "HTML"
    }
    if reply_to:
        payload["reply_to_message_id"] = reply_to
    resp = requests.post(f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage", data=payload)
    return resp.json()["result"] if resp.ok else None

def forward_telegram_message(from_chat_id, message_id, to_chat_id):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/forwardMessage"
    payload = {
        "chat_id": to_chat_id,
        "from_chat_id": from_chat_id,
        "message_id": int(message_id)
    }
    resp = requests.post(url, data=payload)
    return resp.json()["result"] if resp.ok else None

# === –ß—Ç–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
def load_signals():
    download_from_gcs(BUCKET, SIGNALS_FILE, SIGNALS_FILE)
    if os.path.exists(SIGNALS_FILE) and os.path.getsize(SIGNALS_FILE) > 0:
        df = pd.read_csv(SIGNALS_FILE)
    else:
        df = pd.DataFrame(columns=["id", "ticker", "date_sent", "signal_type", "price_entry",
                                   "max_profit", "last_checked", "signal_url", "message_id", "status"])

    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ status –µ—Å—Ç—å
    if "status" not in df.columns:
        df["status"] = "active"

    df["date_sent"] = pd.to_datetime(df["date_sent"], errors='coerce')
    df["last_checked"] = pd.to_datetime(df["last_checked"], errors='coerce')
    return df

# === –°–æ—Ö—Ä–∞–Ω–µ–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤
def save_signals(df):
    df.to_csv(SIGNALS_FILE, index=False)
    upload_to_gcs(SIGNALS_FILE, BUCKET, SIGNALS_FILE)

# === –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
def compute_signals(df, window_days=5, min_vol=1000, min_oi=500, min_ratio=2):
    signals = []
    tickers = df["ticker"].unique()

    for ticker in tickers:
        df_t = df[df["ticker"] == ticker].copy()
        df_t["date"] = pd.to_datetime(df_t["date"], errors='coerce')
        df_t = df_t.dropna(subset=["date", "total_volume", "call_open_interest", "put_open_interest"])
        df_t = df_t.sort_values("date").tail(window_days)

        if len(df_t) < window_days:
            continue

        volumes = df_t["total_volume"].values
        calls = df_t["call_open_interest"].values
        puts = df_t["put_open_interest"].values
        ratios = [c/p if p > 0 else float('inf') for c, p in zip(calls, puts)]

        if (
            volumes[-1] > volumes[0] and
            calls[-1] > calls[0] and
            ratios[-1] > min_ratio and
            volumes[-1] > min_vol and
            calls[-1] > min_oi
        ):
            signals.append({
                "ticker": ticker,
                "volume_trend": f"{int(volumes[0])} ‚Üí {int(volumes[-1])}",
                "oi_trend": f"{int(calls[0])} ‚Üí {int(calls[-1])}",
                "ratio": round(ratios[-1], 2)
            })

    return signals

def send_signals():
    try:
        df = pd.read_csv(STOCK_FILE)
        df = df.dropna(subset=["total_volume", "call_open_interest", "put_open_interest"])
        df["total_volume"] = pd.to_numeric(df["total_volume"], errors='coerce')
        df["call_open_interest"] = pd.to_numeric(df["call_open_interest"], errors='coerce')
        df["put_open_interest"] = pd.to_numeric(df["put_open_interest"], errors='coerce')

        signals = compute_signals(df)
        if not signals:
            print("üö´ –°–∏–≥–Ω–∞–ª–æ–≤ –ø–æ –¥–∏–Ω–∞–º–∏–∫–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            return

        all_signals = load_signals()
        new_rows = []

        for s in signals:
            ticker = s["ticker"]
            signal_type = "BUY"

            if ((all_signals["ticker"] == ticker) & (all_signals["signal_type"] == signal_type)).any():
                print(f"‚è© –£–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω —Ä–∞–Ω–µ–µ: {ticker}")
                continue

            entry_price = yf.Ticker(ticker).history(period="1d")["Close"][-1]
            signal_id = str(uuid.uuid4())[:8]
            today = datetime.now().strftime("%Y-%m-%d")
            url = f"https://t.me/{SIGNAL_CHANNEL.strip('@')}"  # –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Å—Å—ã–ª–∫—É –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø–æ—Å—Ç

            msg = (
                f"üìä –°–∏–≥–Ω–∞–ª: {ticker}\n"
                f"–û–±—ä—ë–º: {s['volume_trend']}\n"
                f"Call OI: {s['oi_trend']}\n"
                f"Call/Put: {s['ratio']}"
            )

            result = send_telegram_message(msg, SIGNAL_CHANNEL)

            if result:
                message_id = result["message_id"]
                channel_username = SIGNAL_CHANNEL.strip("@")
                signal_url = f"https://t.me/{channel_username}/{message_id}"
                print(f"üì§ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {ticker}")
                new_rows.append({
                    "id": signal_id,
                    "ticker": ticker,
                    "date_sent": today,
                    "signal_type": signal_type,
                    "price_entry": entry_price,
                    "max_profit": 0.0,
                    "last_checked": today,
                    "signal_url": signal_url,
                    "message_id": message_id  # üí• –∏–Ω–∞—á–µ –ø–æ—Ç–æ–º –Ω–µ –±—É–¥–µ—Ç reply
                })

        if new_rows:
            all_signals = pd.concat([all_signals, pd.DataFrame(new_rows)], ignore_index=True)
            save_signals(all_signals)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

# === –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–∏–±—ã–ª–∏ –∏ —É–¥–∞–ª–µ–Ω–∏–µ —É–±—ã—Ç–æ—á–Ω—ã—Ö
def drop_from_csv(filepath, tickers, column="ticker"):
    if os.path.exists(filepath):
        df = pd.read_csv(filepath)
        df = df[~df[column].isin(tickers)]
        df.to_csv(filepath, index=False)
        upload_to_gcs(filepath, BUCKET, filepath)

def monitor_signals():
    if not os.path.exists(SIGNALS_FILE):
        return

    df = load_signals()
    updated = []

    # üìå –†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –∞–∫—Ç–∏–≤–Ω—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏
    active_df = df[df["status"] == "active"]

    for _, row in active_df.iterrows():
        ticker = row["ticker"]
        entry = row["price_entry"]
        max_profit = row["max_profit"]
        last_check = pd.to_datetime(row["last_checked"])
        message_id = int(row["message_id"])

        if datetime.now() - last_check < timedelta(days=10):
            row["last_checked"] = datetime.now().strftime("%Y-%m-%d")
            updated.append(row)
            continue

        try:
            price_now = yf.Ticker(ticker).history(period="1d")["Close"][-1]
            profit_pct = ((price_now - entry) / entry) * 100

            row["last_checked"] = datetime.now().strftime("%Y-%m-%d")

            # === –£—Å–ª–æ–≤–∏–µ 1: –ü–µ—Ä–≤–∞—è —Ñ–∏–∫—Å–∞—Ü–∏—è –ø—Ä–∏–±—ã–ª–∏ >20%
            if profit_pct >= 20 and max_profit == 0:
                forward = forward_telegram_message(SIGNAL_CHANNEL, message_id, NEWS_CHANNEL)
                if forward:
                    forward_msg_id = forward["message_id"]
                    news_reply = f"üéâ {ticker} –≤—ã—Ä–æ—Å –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 20%!\nüìà –ü—Ä–∏–±—ã–ª—å: {profit_pct:.2f}%\n–ü–æ–∑–¥—Ä–∞–≤–ª—è–µ–º –≤—Å–µ—Ö!"
                    send_telegram_message(news_reply, NEWS_CHANNEL, reply_to=forward_msg_id)

                reply_signal = f"‚úÖ {ticker} –¥–æ—Å—Ç–∏–≥ —Ü–µ–ª–∏ +20%!\n–¢–µ–∫—É—â–∞—è –ø—Ä–∏–±—ã–ª—å: {profit_pct:.2f}%"
                send_telegram_message(reply_signal, SIGNAL_CHANNEL, reply_to=message_id)

                row["max_profit"] = profit_pct

            # === –£—Å–ª–æ–≤–∏–µ 2: –ù–æ–≤—ã–π –º–∞–∫—Å–∏–º—É–º
            elif profit_pct > max_profit:
                forward = forward_telegram_message(SIGNAL_CHANNEL, message_id, NEWS_CHANNEL)
                if forward:
                    forward_msg_id = forward["message_id"]
                    news_reply = f"üìà {ticker} –æ–±–Ω–æ–≤–∏–ª –º–∞–∫—Å–∏–º—É–º: +{profit_pct:.2f}%"
                    send_telegram_message(news_reply, NEWS_CHANNEL, reply_to=forward_msg_id)

                reply_signal = f"üìà –ù–æ–≤—ã–π –º–∞–∫—Å–∏–º—É–º –ø—Ä–∏–±—ã–ª–∏ –ø–æ {ticker}: +{profit_pct:.2f}%"
                send_telegram_message(reply_signal, SIGNAL_CHANNEL, reply_to=message_id)

                row["max_profit"] = profit_pct

            # === –£—Å–ª–æ–≤–∏–µ 3: –ü—Ä–∏–±—ã–ª—å –ø–∞–¥–∞–µ—Ç ‚Üí —Å—Ç–∞—Ç—É—Å closed
            elif profit_pct < max_profit:
                print(f"üõë {ticker} ‚Äî –ø—Ä–∏–±—ã–ª—å —É–ø–∞–ª–∞, –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ closed")
                row["status"] = "closed"

            updated.append(row)

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ {ticker}: {e}")
            updated.append(row)

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é
    closed_df = df[df["status"] == "closed"]
    final_df = pd.concat([pd.DataFrame(updated), closed_df], ignore_index=True)

    save_signals(final_df)

    if dropped:
        drop_from_csv(STOCK_FILE, dropped)
        drop_from_csv(PORTFOLIO_FILE, dropped)
        drop_from_csv(SIGNALS_FILE, dropped)
        print(f"üßπ –£–¥–∞–ª–µ–Ω—ã —Ç–∏–∫–µ—Ä—ã: {dropped}")

# === –ó–∞–ø—É—Å–∫
send_signals()
monitor_signals()

print("üéØ DONE ver. 2")


