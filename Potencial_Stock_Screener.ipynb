{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_Xd4jZlbQtU",
        "outputId": "8d67ea55-9e7f-4f65-d0e5-22ba0b98cd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.64)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.11.4)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.0)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install requests pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# üîê –ó–ê–ú–ï–ù–ò –≠–¢–ò –î–ê–ù–ù–´–ï –ù–ê –°–í–û–ò\n",
        "API_KEY = \"AIzaSyDcEWk0DMenYS60petfPlVH5-9Zp5PgzWc\"\n",
        "CX = \"863020016f9014413\"\n",
        "\n",
        "# üìå –ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã\n",
        "current_month = datetime.now().strftime(\"%B\")\n",
        "current_year = datetime.now().year\n",
        "\n",
        "queries = [\n",
        "    f\"Top stocks to buy {current_month} {current_year}\",\n",
        "    f\"Best stocks to invest in {current_month} {current_year}\",\n",
        "    f\"Growth stocks to buy now {current_year}\",\n",
        "    \"Best stocks to buy now\",\n",
        "]\n",
        "\n",
        "# üìÅ –ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ CSV\n",
        "csv_file = \"Stocks.csv\"\n",
        "\n",
        "# üì• –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –µ—Å—Ç—å\n",
        "try:\n",
        "    df_old = pd.read_csv(csv_file)\n",
        "except FileNotFoundError:\n",
        "    df_old = pd.DataFrame(columns=[\"ticker\", \"date\", \"source\", \"link\"])\n",
        "existing = set(zip(df_old[\"ticker\"], df_old[\"source\"], df_old[\"link\"]))\n",
        "new_data = []\n",
        "\n",
        "# üîç –ü–æ–∏—Å–∫ –∏ –ø–∞—Ä—Å–∏–Ω–≥\n",
        "for query in queries:\n",
        "    print(f\"üîç –ü–æ–∏—Å–∫: {query}\")\n",
        "    params = {\n",
        "        \"key\": API_KEY,\n",
        "        \"cx\": CX,\n",
        "        \"q\": query,\n",
        "        \"num\": 10,\n",
        "    }\n",
        "    response = requests.get(\"https://www.googleapis.com/customsearch/v1\", params=params)\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "\n",
        "    for item in data.get(\"items\", []):\n",
        "        title = item.get(\"title\", \"\")\n",
        "        snippet = item.get(\"snippet\", \"\")\n",
        "        link = item.get(\"link\", \"\")\n",
        "        source = re.sub(r\"https?://(www\\.)?\", \"\", link).split(\"/\")[0]\n",
        "\n",
        "        # üîé –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å —Ç–∏–∫–µ—Ä—ã (–≤—Å—ë –≤ –≤–µ—Ä—Ö–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ, –æ—Ç 1 –¥–æ 5 –±—É–∫–≤)\n",
        "        tickers = set(re.findall(r\"\\b[A-Z]{1,5}\\b\", title + \" \" + snippet))\n",
        "\n",
        "        # –§–∏–ª—å—Ç—Ä –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ ‚Äî –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å\n",
        "        tickers = [t for t in tickers if t.isalpha() and 1 <= len(t) <= 5]\n",
        "\n",
        "        for ticker in tickers:\n",
        "            if not ((df_old[\"ticker\"] == ticker) & (df_old[\"link\"] == link)).any():\n",
        "                new_data.append({\n",
        "                  \"ticker\": ticker,\n",
        "                  \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "                  \"source\": source,\n",
        "                  \"link\": link\n",
        "                })\n",
        "# === 2. üöÄ SPACInsider ===\n",
        "try:\n",
        "    spac_url = \"https://www.spacinsider.com/stats/\"\n",
        "    response = requests.get(spac_url)\n",
        "    soup = BeautifulSoup(response.text, \"lxml\")\n",
        "    tables = soup.find_all(\"table\")\n",
        "\n",
        "    for table in tables:\n",
        "        if \"Estimated Deadline\" in table.text:\n",
        "            rows = table.find_all(\"tr\")[1:]\n",
        "            for row in rows:\n",
        "                cols = row.find_all(\"td\")\n",
        "                if len(cols) < 5:\n",
        "                    continue\n",
        "                ticker = cols[1].text.strip()\n",
        "                deadline_str = cols[-1].text.strip()\n",
        "                try:\n",
        "                    deadline = datetime.strptime(deadline_str, \"%m/%d/%Y\")\n",
        "                    days_left = (deadline - datetime.now()).days\n",
        "                    if 0 < days_left <= 120:\n",
        "                        key = (ticker, \"SPAC\", spac_url)\n",
        "                        if key not in existing:\n",
        "                            new_data.append({\n",
        "                                \"ticker\": ticker,\n",
        "                                \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "                                \"source\": \"SPAC\",\n",
        "                                \"link\": spac_url\n",
        "                            })\n",
        "                            existing.add(key)\n",
        "                except:\n",
        "                    continue\n",
        "            break\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ SPAC: {e}\")\n",
        "\n",
        "# === 3. üíä FDA Calendar (BioPharmCatalyst) ===\n",
        "try:\n",
        "    fda_url = \"https://www.biopharmcatalyst.com/calendars/fda-calendar\"\n",
        "    response = requests.get(fda_url)\n",
        "    soup = BeautifulSoup(response.text, \"lxml\")\n",
        "    rows = soup.select(\"table tr\")\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(\"td\")\n",
        "        if len(cols) < 4:\n",
        "            continue\n",
        "        date_str = cols[0].text.strip()\n",
        "        try:\n",
        "            event_date = datetime.strptime(date_str, \"%b %d, %Y\")\n",
        "        except:\n",
        "            continue\n",
        "        if 0 <= (event_date - datetime.now()).days <= 30:\n",
        "            ticker = cols[1].text.strip()\n",
        "            key = (ticker, \"FDA\", fda_url)\n",
        "            if key not in existing:\n",
        "                new_data.append({\n",
        "                    \"ticker\": ticker,\n",
        "                    \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "                    \"source\": \"FDA\",\n",
        "                    \"link\": fda_url\n",
        "                })\n",
        "                existing.add(key)\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ FDA: {e}\")\n",
        "\n",
        "# üì¶ –°–æ—Ö—Ä–∞–Ω—è–µ–º\n",
        "if new_data:\n",
        "    df_new = pd.DataFrame(new_data)\n",
        "    df_total = pd.concat([df_old, df_new], ignore_index=True)\n",
        "    df_total.to_csv(csv_file, index=False)\n",
        "    print(f\"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(new_data)}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A844UIy_Ch7Z",
        "outputId": "207611b5-d3b3-4af2-e122-46215e8abed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç –ü–æ–∏—Å–∫: Top stocks to buy July 2025\n",
            "üîç –ü–æ–∏—Å–∫: Best stocks to invest in July 2025\n",
            "üîç –ü–æ–∏—Å–∫: Growth stocks to buy now 2025\n",
            "üîç –ü–æ–∏—Å–∫: Best stocks to buy now\n",
            "‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ===\n",
        "DATA_DIR = \"options_data\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "TODAY = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "CSV_PATH = \"Stocks.csv\"  # <-- –ø—É—Ç—å –∫ —Ç–≤–æ–µ–º—É —Å–ø–∏—Å–∫—É —Ç–∏–∫–µ—Ä–æ–≤\n",
        "\n",
        "# === –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–∏–∫–µ—Ä–æ–≤ ===\n",
        "df_stocks = pd.read_csv(CSV_PATH, sep=',')\n",
        "tickers = df_stocks['ticker'].dropna().unique().tolist()\n",
        "\n",
        "# === –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ –∫–∞–∂–¥–æ–º—É —Ç–∏–∫–µ—Ä—É ===\n",
        "for ticker in tickers:\n",
        "    try:\n",
        "        stock = yf.Ticker(ticker)\n",
        "        expirations = stock.options\n",
        "        if not expirations:\n",
        "            print(f\"[{ticker}] ‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ–ø—Ü–∏–æ–Ω–æ–≤\")\n",
        "            continue\n",
        "\n",
        "        expiry = expirations[0]  # –±–ª–∏–∂–∞–π—à–∞—è –¥–∞—Ç–∞\n",
        "        opt_chain = stock.option_chain(expiry)\n",
        "\n",
        "        # –û–±—ä–µ–¥–∏–Ω—è–µ–º Calls –∏ Puts\n",
        "        calls = opt_chain.calls.copy()\n",
        "        puts = opt_chain.puts.copy()\n",
        "        calls[\"type\"] = \"call\"\n",
        "        puts[\"type\"] = \"put\"\n",
        "\n",
        "        options = pd.concat([calls, puts])\n",
        "        options[\"expirationDate\"] = expiry\n",
        "        options[\"fetchDate\"] = TODAY\n",
        "\n",
        "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV\n",
        "        filename = f\"{DATA_DIR}/options_{ticker}_{TODAY}.csv\"\n",
        "        options.to_csv(filename, index=False)\n",
        "        print(f\"[{ticker}] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[{ticker}] ‚ùå –û—à–∏–±–∫–∞: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "It9ojxwlbRvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ce8575-eacc-4d1b-d18c-f90f252f736d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BLBD] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_BLBD_2025-07-07.csv\n",
            "[CWAN] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_CWAN_2025-07-07.csv\n",
            "[DOCU] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_DOCU_2025-07-07.csv\n",
            "[FLR] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_FLR_2025-07-07.csv\n",
            "[ITRN] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_ITRN_2025-07-07.csv\n",
            "[KSPI] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_KSPI_2025-07-07.csv\n",
            "[PDD] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_PDD_2025-07-07.csv\n",
            "[PINS] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_PINS_2025-07-07.csv\n",
            "[QSG] ‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ–ø—Ü–∏–æ–Ω–æ–≤\n",
            "[NVDA] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_NVDA_2025-07-07.csv\n",
            "[TW] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_TW_2025-07-07.csv\n",
            "[ORCL] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_ORCL_2025-07-07.csv\n",
            "[JBL] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_JBL_2025-07-07.csv\n",
            "[EPS] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_EPS_2025-07-07.csv\n",
            "[AI] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_AI_2025-07-07.csv\n",
            "[JNJ] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_JNJ_2025-07-07.csv\n",
            "[PFE] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_PFE_2025-07-07.csv\n",
            "[BRK] ‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ–ø—Ü–∏–æ–Ω–æ–≤\n",
            "[B] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_B_2025-07-07.csv\n",
            "[EIX] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_EIX_2025-07-07.csv\n",
            "[PCG] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_PCG_2025-07-07.csv\n",
            "[E] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_E_2025-07-07.csv\n",
            "[PG] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_PG_2025-07-07.csv\n",
            "[LMT] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_LMT_2025-07-07.csv\n",
            "[STT] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_STT_2025-07-07.csv\n",
            "[U] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_U_2025-07-07.csv\n",
            "[S] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_S_2025-07-07.csv\n",
            "[DTE] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_DTE_2025-07-07.csv\n",
            "[VERV] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_VERV_2025-07-07.csv\n",
            "[PHAT] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_PHAT_2025-07-07.csv\n",
            "[NKTR] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_NKTR_2025-07-07.csv\n",
            "[NVMI] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_NVMI_2025-07-07.csv\n",
            "[MNDY] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_MNDY_2025-07-07.csv\n",
            "[PLTR] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_PLTR_2025-07-07.csv\n",
            "[INTU] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_INTU_2025-07-07.csv\n",
            "[LLY] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_LLY_2025-07-07.csv\n",
            "[AVGO] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_AVGO_2025-07-07.csv\n",
            "[NOW] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_NOW_2025-07-07.csv\n",
            "[I] ‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ–ø—Ü–∏–æ–Ω–æ–≤\n",
            "[DGNX] ‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ–ø—Ü–∏–æ–Ω–æ–≤\n",
            "[EPSM] ‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ–ø—Ü–∏–æ–Ω–æ–≤\n",
            "[NYSE] ‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ–ø—Ü–∏–æ–Ω–æ–≤\n",
            "[TOST] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_TOST_2025-07-07.csv\n",
            "[ELF] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_ELF_2025-07-07.csv\n",
            "[AMZN] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_AMZN_2025-07-07.csv\n",
            "[US] ‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ–ø—Ü–∏–æ–Ω–æ–≤\n",
            "[GE] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_GE_2025-07-07.csv\n",
            "[NFLX] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_NFLX_2025-07-07.csv\n",
            "[GOOGL] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_GOOGL_2025-07-07.csv\n",
            "[MSFT] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ options_data/options_MSFT_2025-07-07.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# === –¢–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ –±–æ—Ç–∞ ===\n",
        "BOT_TOKEN = \"8063786817:AAGKrA2Y7PKM5NT_STM6mFMLVBeQzv2QBws\"\n",
        "CHAT_ID = \"@insiderpulseaichannel\"\n",
        "SIGNAL_FILE = \"buy_signals.csv\"\n",
        "\n",
        "def send_telegram_message(text):\n",
        "    url = f\"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage\"\n",
        "    response = requests.post(url, data={\"chat_id\": CHAT_ID, \"text\": text})\n",
        "    return response.status_code == 200\n",
        "\n",
        "def send_signals():\n",
        "    try:\n",
        "        df = pd.read_csv(SIGNAL_FILE)\n",
        "        today = pd.Timestamp.now().strftime(\"%Y-%m-%d\")\n",
        "        df_today = df[df[\"date\"] == today]\n",
        "        if df_today.empty:\n",
        "            print(\"–ù–µ—Ç —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è.\")\n",
        "            return\n",
        "        for _, row in df_today.iterrows():\n",
        "            message = (\n",
        "                f\"üìà –°–∏–≥–Ω–∞–ª –Ω–∞ –ø–æ–∫—É–ø–∫—É: {row['ticker']}\\n\"\n",
        "                f\"–û–±—ä—ë–º: {row['avg_volume']} | OI: {row['avg_oi']}\\n\"\n",
        "                f\"Call/Put: {row['call_put_ratio']}\"\n",
        "            )\n",
        "            send_telegram_message(message)\n",
        "            print(f\"üì§ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {row['ticker']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}\")\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫\n",
        "send_signals()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWafcELDd1ev",
        "outputId": "03c4dff2-34d2-42f4-fc6f-51ea19026859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: [Errno 2] No such file or directory: 'buy_signals.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "bxGfYgNzbula"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}